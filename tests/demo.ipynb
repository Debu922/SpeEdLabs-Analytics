{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Analytics Demo\n",
    "\n",
    "\n",
    "## Generation of Metrics\n",
    "\n",
    "We first identify the metrics that we are interested in tracking. The most interesting metrics are:\n",
    "* \"NoQ\" - Number of Questions attempted by user / global average in session / subject / chapter\n",
    "* \"Att\" - What percentage of questions seen have been attempted\n",
    "* \"Acc\" - What percentage of the questions \n",
    "* \"STim\" - Time taken for the session\n",
    "* \"ATim\" - Time taken for each question\n",
    "* \"KSC\" - What percentage of seen questions was the KSC viewed.\n",
    "* \"Soln\" - What percentage of seen questions was the full solution viewed.\n",
    "* \"Att2\" - What percentage of the incorrectly answered questions were tried again.\n",
    "* \"Acc2\" - What percentage of the incorrectly answered questions were correctly answered in the second try.\n",
    "* \"Revw\" - What percentage of the total questions were marked for review.\n",
    "\n",
    "We are interested in reporting session metrics for students. To proceed with the analysis we do a top down approach. The hierarchy is\n",
    "* Course\n",
    "    * Subject:   \n",
    "        * Topic:\n",
    "            * Chapter:\n",
    "                * KSC:\n",
    "                \n",
    "A session includes one or more chapters from the same subject. So we are interested in finding one or more chapte\n",
    "To hold the data we propose two classes\n",
    "* Global: Responsible for storing global metrics for subject, chapter and pseudosession.\n",
    "* User: Responsible for storing user metrics for subject, chappter and session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Feedback\n",
    "\n",
    "After the generation of metrics, we want to produce user feedback. The way to go about that is by calculating z-scores of student vs student (previous) and student vs global metrics.\n",
    "\n",
    "By using predefined z-score metrics we can provide approrpiate metrics as and when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft SQL Server 2016 (SP1-CU15-GDR) (KB4505221) - 13.0.4604.0 (X64) \n",
      "\tJun 15 2019 07:56:34 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tDeveloper Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if \"Imports\":\n",
    "    import sys\n",
    "    import os\n",
    "    import json\n",
    "    sys.path.append(os.getcwd() + \"\\..\\src\")\n",
    "    from user import User\n",
    "    from institute import Institute\n",
    "    from util import *\n",
    "    from db_util import DBConnection\n",
    "    from IPython.display import display\n",
    "    from feedback import FeedbackEngine\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "# Setup connection to DB and initate sample query\n",
    "cnxnObj = DBConnection()\n",
    "cnxn = cnxnObj.connection\n",
    "cnxnObj.sample_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedbackEngine initialization complete\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "with open(\"../config.json\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# initiate FeedbackEngine\n",
    "feedbackEngine = FeedbackEngine(cnxn, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Class Generated\n",
      "Institute Class Generated\n",
      "User Session Metrics Generated\n",
      "Pseudo Session Metrics Generated\n",
      "User Subject Metrics Generated\n",
      "Finished Generating Session Wise Metrics\n",
      "User Session History Metrics Generated\n",
      "SessionZScore calculated\n",
      "Feedback List Generated successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acc</td>\n",
       "      <td>Session vs Pseudo Session</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.350955</td>\n",
       "      <td>Your accuracy is {_userAccuracy} where as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acc</td>\n",
       "      <td>Session vs Subject History</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.582863</td>\n",
       "      <td>Your accuracy is {_userAccuracy} where as your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acc</td>\n",
       "      <td>Session vs Session History</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.188800</td>\n",
       "      <td>Your accuracy is {_userAccuracy} where as your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STim</td>\n",
       "      <td>Session vs Pseudo Session</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.641275</td>\n",
       "      <td>You took {_userTime} to finish the session whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STim</td>\n",
       "      <td>Session vs Subject History</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.886461</td>\n",
       "      <td>You took {_userTime} to finish the session whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STim</td>\n",
       "      <td>Session vs Session History</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.027941</td>\n",
       "      <td>You took {_userTime} to finish the session whe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                        type id     score  \\\n",
       "0    Acc   Session vs Pseudo Session  0 -1.350955   \n",
       "1    Acc  Session vs Subject History  0 -1.582863   \n",
       "2    Acc  Session vs Session History  0 -2.188800   \n",
       "3   STim   Session vs Pseudo Session  0 -0.641275   \n",
       "4   STim  Session vs Subject History  0 -0.886461   \n",
       "5   STim  Session vs Session History  0 -1.027941   \n",
       "\n",
       "                                                text  \n",
       "0  Your accuracy is {_userAccuracy} where as the ...  \n",
       "1  Your accuracy is {_userAccuracy} where as your...  \n",
       "2  Your accuracy is {_userAccuracy} where as your...  \n",
       "3  You took {_userTime} to finish the session whe...  \n",
       "4  You took {_userTime} to finish the session whe...  \n",
       "5  You took {_userTime} to finish the session whe...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionQualityFeedbackList = feedbackEngine.gen_session_quality_feedback_list(729884,20)\n",
    "display(sessionQualityFeedbackList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Class Already exists, fetching existing user data\n",
      "Institute Class already exists, fetching existing institute data\n",
      "User Session Metrics Generated\n",
      "Institute Topic Metrics Generated\n",
      "Feedback List Generated successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoQ</td>\n",
       "      <td>Session vs Global Topic</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.232182</td>\n",
       "      <td>You attempted {_userAttempt} questions where a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STim</td>\n",
       "      <td>Session vs Global Topic</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.380070</td>\n",
       "      <td>You took much less time than others.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                     type id     score  \\\n",
       "0    NoQ  Session vs Global Topic  1 -0.232182   \n",
       "1   STim  Session vs Global Topic  0 -0.380070   \n",
       "\n",
       "                                                text  \n",
       "0  You attempted {_userAttempt} questions where a...  \n",
       "1               You took much less time than others.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionQuantityFeedbackList = feedbackEngine.get_session_quantity_feedback_list(729884)\n",
    "display(sessionQuantityFeedbackList)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "553d7a684a0e40235345afdd810e085cec4317ba0f9ba21e174e18404b011a1c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
